# -*- coding: utf-8 -*-
"""22-pr1-MasterCard Stock Price Prediction Using LSTM & GRU.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/17ajbCNwU1IK-OfCmfb7H6uZvLyT6WRUB

<br>

# RNN Project3: MasterCard Stock Price Prediction Using LSTM & GRU

| Prepared by: | Rayyan Ahmed |
|-------------|--------------|
| Date: | 25th May, 2025 |

<br>
"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt

from sklearn.preprocessing import MinMaxScaler
from sklearn.metrics import mean_squared_error

from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, LSTM, Dropout, GRU, Bidirectional
from tensorflow.keras.optimizers import SGD
from tensorflow.random import set_seed

set_seed(455)
np.random.seed(455)

dataset = pd.read_csv("Mastercard_stock_history.csv")
dataset

dataset.isnull().sum()

dataset.describe()

dataset.loc[f"{2016}":f"{2021}", "High"]

import pandas as pd
import matplotlib.pyplot as plt

# Assuming your df has a 'Date' column
dataset['Date'] = pd.to_datetime(dataset['Date'])
dataset.set_index('Date', inplace=True)

tstart = 2016
tend = 2020

def train_test_plot(dataset, tstart, tend):
    dataset.loc[f"{tstart}":f"{tend}", "High"].plot(figsize=(16, 4), legend=True)
    dataset.loc[f"{tend+1}":, "High"].plot(figsize=(16, 4), legend=True)
    plt.legend([f"Train (Before {tend+1})", f"Test ({tend+1} and beyond)"])
    plt.title("MasterCard stock price")
    plt.grid()
    plt.show()

train_test_plot(dataset, tstart, tend)

dataset.loc[f"{tstart}":f"{tend}", "High"].head(60)
dataset.loc[f"{tend+1}":, "High"]

def train_test_split(dataset, tstart, tend):
    train = dataset.loc[f"{tstart}":f"{tend}", "High"].values
    test = dataset.loc[f"{tend+1}":, "High"].values
    return train, test
training_set, test_set = train_test_split(dataset, tstart, tend)

training_set[0:59]

training_set[60]

test_set

training_set.shape, test_set.shape

sc = MinMaxScaler(feature_range=(0, 1))
training_set = training_set.reshape(-1, 1)
training_set_scaled = sc.fit_transform(training_set)

training_set, training_set_scaled[60]

def split_sequence(sequence, n_steps):
    X, y = list(), list()
    for i in range(len(sequence)):
        end_ix = i + n_steps
        if end_ix > len(sequence) - 1:
            break
        seq_x, seq_y = sequence[i:end_ix], sequence[end_ix]
        X.append(seq_x)
        y.append(seq_y)
    return np.array(X), np.array(y)


n_steps = 60
features = 1
# split into samples
X_train, y_train = split_sequence(training_set_scaled, n_steps)

X_train

y_train

print(X_train.shape), print(y_train.shape)

X_train = X_train.reshape(X_train.shape[0],X_train.shape[1],features)

# The LSTM architecture
model_lstm = Sequential()
model_lstm.add(LSTM(units=125, activation="tanh", input_shape=(n_steps, features)))
model_lstm.add(Dense(units=1))
# Compiling the model
model_lstm.compile(optimizer="RMSprop", loss="mse")

model_lstm.summary()

model_lstm.fit(X_train, y_train, epochs=50, batch_size=32, validation_split = 0.2)

dataset_total = dataset.loc[:,"High"]
inputs = dataset_total[len(dataset_total) - len(test_set) - n_steps :].values
inputs = inputs.reshape(-1, 1)
#scaling
inputs = sc.transform(inputs)

# Split into samples
X_test, y_test = split_sequence(inputs, n_steps)
# reshape
X_test = X_test.reshape(X_test.shape[0], X_test.shape[1], features)
#prediction
predicted_stock_price = model_lstm.predict(X_test)
#inverse transform the values
predicted_stock_price = sc.inverse_transform(predicted_stock_price)

def plot_predictions(test, predicted):
    plt.plot(test, color="gray", label="Real")
    plt.plot(predicted, color="red", label="Predicted")
    plt.title("MasterCard Stock Price Prediction")
    plt.xlabel("Time")
    plt.ylabel("MasterCard Stock Price")
    plt.legend()
    plt.show()


def return_rmse(test, predicted):
    rmse = np.sqrt(mean_squared_error(test, predicted))
    print("The root mean squared error is {:.2f}.".format(rmse))

plt.grid()
plot_predictions(test_set,predicted_stock_price)

model_gru = Sequential()
model_gru.add(GRU(units=125, activation="tanh", input_shape=(n_steps, features)))
model_gru.add(Dense(units=1))
# Compiling the RNN
model_gru.compile(optimizer="RMSprop", loss="mse")

model_gru.summary()

model_gru.fit(X_train, y_train, epochs=50, batch_size=32)

GRU_predicted_stock_price = model_gru.predict(X_test)
GRU_predicted_stock_price = sc.inverse_transform(GRU_predicted_stock_price)
plot_predictions(test_set, GRU_predicted_stock_price)

return_rmse(test_set,GRU_predicted_stock_price)

import os

# Make sure 'model' directory exists
os.makedirs("model", exist_ok=True)

# Save models and scaler in 'model/' folder
import joblib

model_gru.save("model/model_gru.keras")
model_lstm.save("model/model_lstm.keras")
joblib.dump(sc, "model/stckmark_scaler.save")
